name: ðŸ¤– Gemini AI Production PDR Processing

on:
  workflow_dispatch:
    inputs:
      date:
        description: 'Target date (YYYY-MM-DD)'
        required: true
        default: '2025-07-14'
      instructions:
        description: 'Additional processing instructions (optional)'
        required: false
        default: ''

jobs:
  gemini-pdr-processing:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      issues: write
      pull-requests: write
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Check Bridge Health & Extract WhatsApp Messages
      env:
        GH_TOKEN: ${{ secrets.PAT_WITH_CODESPACE }}
      id: extract
      run: |
        CODESPACE_NAME="cuddly-guacamole-496vp6p46wg39r"
        TARGET_DATE="${{ github.event.inputs.date }}"
        
        echo "ðŸ” Checking WhatsApp bridge health and extracting messages for $TARGET_DATE..."
        
        # Check if bridge service is running and restart if needed
        echo "ðŸ”§ Checking bridge service status..."
        BRIDGE_STATUS=$(gh codespace ssh -c $CODESPACE_NAME -- \
          "cd /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge && ./start-bridge-service.sh status" 2>/dev/null || echo "Bridge not running")
        
        if [[ "$BRIDGE_STATUS" == *"not running"* ]]; then
          echo "ðŸš¨ Bridge not running - starting service..."
          gh codespace ssh -c $CODESPACE_NAME -- \
            "cd /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge && ./start-bridge-service.sh start"
          sleep 10  # Give bridge time to start
          echo "âœ… Bridge service started"
        else
          echo "âœ… Bridge service is running"
        fi
        
        # Extract messages from Codespace SQLite database
        echo "ðŸ“‹ Extracting messages with production keywords..."
        gh codespace ssh -c $CODESPACE_NAME -- \
          "sqlite3 /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge/store/messages.db \"SELECT timestamp, chat_jid, sender, content FROM messages WHERE timestamp BETWEEN '${TARGET_DATE} 00:00:00+00:00' AND '${TARGET_DATE} 23:59:59+00:00' AND chat_jid = '27834418149-1537194373@g.us' AND (content LIKE '%ROM%' OR content LIKE '%Safety%' OR content LIKE '%Gloria Report%' OR content LIKE '%Nchwaning%' OR content LIKE '%S&W%' OR content LIKE '%Decline%' OR content LIKE '%Product%' OR content LIKE '%Loads%') ORDER BY timestamp;\"" > extracted_messages.txt
        
        # Count messages and validate extraction
        MESSAGE_COUNT=$(wc -l < extracted_messages.txt)
        echo "ðŸ“Š Found $MESSAGE_COUNT WhatsApp messages for $TARGET_DATE"
        
        # Output variables for next steps
        echo "message_count=$MESSAGE_COUNT" >> $GITHUB_OUTPUT
        echo "target_date=$TARGET_DATE" >> $GITHUB_OUTPUT
        
        # Save extracted data for Gemini processing
        if [ "$MESSAGE_COUNT" -gt 0 ]; then
          cp extracted_messages.txt whatsapp_data_for_gemini.txt
          echo "data_file_created=true" >> $GITHUB_OUTPUT
        else
          echo "data_file_created=false" >> $GITHUB_OUTPUT
        fi
        
        # Preview extracted data (first 3 lines)
        echo "ðŸ“‹ Message preview:"
        head -3 extracted_messages.txt || echo "No data to preview"
    
    - name: Handle No Data Found
      env:
        GH_TOKEN: ${{ secrets.PAT_WITH_CODESPACE }}
      if: steps.extract.outputs.message_count == '0'
      run: |
        TARGET_DATE="${{ steps.extract.outputs.target_date }}"
        echo "ðŸ›‘ STOPPING PROCESSING - No data available for $TARGET_DATE"
        echo "Possible reasons:"
        echo "  - Date may be a weekend/holiday with no reports"
        echo "  - Bridge may have been offline during report time"
        echo "  - Reports may use different keywords not in search filter"
        echo "  - Date format may be incorrect (use YYYY-MM-DD)"
        
        # Create a no-data notification issue
        gh issue create \
          --title "âŒ No Data Found (Gemini Production): $TARGET_DATE" \
          --body "**No production data available for $TARGET_DATE**

        ðŸ“Š **Search Results**: 0 messages found
        ðŸ” **Search Criteria**: ROM, Production, Gloria, Nchwaning, S&W keywords
        â° **Time Range**: Full day (00:00-23:59 UTC)
        ðŸ¤– **Processing**: Gemini AI Production workflow
        
        **Possible Reasons**:
        - Weekend/holiday - no production reports sent
        - WhatsApp bridge offline during report time (4:00-6:00 AM SAST)
        - Engineers used different messaging keywords
        - Date format incorrect or date does not exist
        
        **Bridge Status**: Checked and restarted if needed
        **Recommendation**: Verify date and retry, or process manually if reports exist" \
          --label "no-data" \
          --label "pdr-gemini"
        
        echo "âœ… Created no-data notification issue"
        
    - name: Process with Gemini AI (Production Logic)
      uses: 'google-github-actions/run-gemini-cli@v0'
      id: gemini_process
      if: steps.extract.outputs.message_count > 0
      env:
        TARGET_DATE: ${{ github.event.inputs.date }}
        MESSAGE_COUNT: ${{ steps.extract.outputs.message_count }}
      with:
        gemini_api_key: ${{ secrets.GEMINI_API_KEY }}
        settings: |-
          {
            "maxSessionTurns": 50,
            "autoAccept": ["list_directory", "read_file", "write_file", "glob"],
            "telemetry": {
              "enabled": false,
              "target": "gcp"
            }
          }
        prompt: |-
          ## Role
          
          You are a specialized AI assistant for processing daily production reports for Assmang's Black Rock mining operations. You have full access to all available tools to interact with the repository, create files, and manage the workflow.
          
          ## Context
          
          - **Repository**: `${{ github.repository }}`
          - **Processing Date**: `${{ github.event.inputs.date }}`
          - **Messages Found**: `${{ steps.extract.outputs.message_count }}`
          - **Data Source**: WhatsApp production reports from mine engineers
          - **Output Required**: JSON and Markdown files for each mine site
          
          ## Task: Daily Production Report Processing
          
          You need to process WhatsApp production data and create comprehensive daily reports for each detected mine site.
          
          **SITES TO PROCESS**:
          - Gloria Mine (Engineer: Sipho Dubazane)
          - Nchwaning 2 (Engineer: Sikelela Nzuza) 
          - Nchwaning 3 (Engineer: Sello Sease)
          - Shafts & Winders (Engineer: Xavier Peterson)
          
          ## How to Process Production Reports
          
          ### Step 1: Create and Maintain a Plan
          **Show and maintain a plan as a checklist**:
          - At the very beginning, outline the steps needed to process the production data
          - Create a plan comment in the workflow logs or as output
          - Example plan:
            ```
            ### Production Report Processing Plan
            - [ ] Read and analyze WhatsApp data source
            - [ ] Identify mine sites present in data
            - [ ] Extract production metrics for each site
            - [ ] Create JSON files with structured data
            - [ ] Create Markdown reports for readability
            - [ ] Validate all data points against source
            - [ ] Confirm file creation and structure
            ```
          
          ### Step 2: Data Analysis and Extraction
          1. **Read the source data**: Use `cat whatsapp_data_for_gemini.txt` or appropriate tools to examine the WhatsApp production data
          2. **Identify mine sites**: Look for mentions of Gloria, Nchwaning 2, Nchwaning 3, and Shafts & Winders
          3. **Extract key metrics**: 
             - Safety status and incidents
             - Production figures (ROM, Product, Decline, Loads)
             - Equipment availability (DT, FL percentages)
             - Silo/Dam levels where applicable
          
          ### Step 3: File Creation
          **Create files using available tools**:
          
          **Directory Structure**: `daily_production/data/YYYY-MM/DD/`
          
          **For each site found in data:**
          
          1. **JSON File** (`YYYY-MM-DD_[site].json`):
             ```json
             {
               "report_metadata": {
                 "date": "${{ github.event.inputs.date }}",
                 "site": "[Site Name]",
                 "engineer": "[Engineer Name]",
                 "processing_method": "gemini_ai_automated"
               },
               "safety": {
                 "status": "[extracted from source]",
                 "incidents": [number]
               },
               "production": {
                 "rom": {"actual": [number], "unit": "tonnes"},
                 "decline": {"actual": [number], "unit": "metres"},
                 "product": {"actual": [number], "unit": "tonnes"}
               },
               "equipment_availability": {
                 "tmm": {
                   "DT": [percentage],
                   "FL": [percentage]
                 }
               },
               "source_validation": {
                 "rom_actual": {
                   "value": [number],
                   "source_quote": "[exact text from WhatsApp]",
                   "confidence": "HIGH|MEDIUM|LOW"
                 }
               }
             }
             ```
          
          2. **Markdown File** (`YYYY-MM-DD â€“ [Site Name] Daily Report.md`):
             - Professional summary of the day's operations
             - Key production metrics highlighted
             - Safety status and any incidents
             - Equipment performance summary
             - Issues or concerns noted
          
          ### Step 4: Data Validation Requirements
          
          **CRITICAL DATA INTEGRITY RULES**:
          - **NEVER INVENT DATA**: Extract only actual values from the WhatsApp source
          - **Source Traceability**: Every data point must reference the exact source text
          - **Use null for missing data**: If a metric isn't in the source, use `null`
          - **Quote Accuracy**: Include exact quotes from WhatsApp messages
          - **Confidence Levels**: Mark data confidence as HIGH/MEDIUM/LOW based on clarity
          
          ### Step 5: File Organization and Verification
          
          1. **Create proper directory structure**: Use tools to ensure `daily_production/data/YYYY-MM/DD/` exists
          2. **Write files**: Use appropriate file writing tools to create both JSON and Markdown files
          3. **Verify creation**: List directory contents to confirm files were created successfully
          4. **Validate structure**: Check that file paths follow the expected naming convention
          
          ## Guidelines
          
          - **Be systematic and thorough**: Follow the checklist plan step by step
          - **Maintain data integrity**: Every piece of data must be traceable to the source
          - **Use all available tools**: You have access to file operations, directory management, and analysis tools
          - **Create professional output**: Both JSON and Markdown should be well-formatted and complete
          - **Handle errors gracefully**: If data is missing or unclear, document this in the output
          - **Follow project conventions**: Use the established file naming and directory structure
          
          ## Success Criteria
          
          - [ ] WhatsApp data successfully analyzed
          - [ ] All mine sites identified and processed
          - [ ] JSON files created with complete schema
          - [ ] Markdown reports generated for readability
          - [ ] All data points validated against source
          - [ ] Files properly organized in directory structure
          - [ ] Processing plan completed and verified
          
          **Begin processing the production data for ${{ github.event.inputs.date }} now.**
          
          ## Available Tools
          
          You have access to all available MCP (Model Context Protocol) tools including:
          - **File Operations**: `write_file`, `read_file`, `list_files` for creating and managing files
          - **Directory Management**: Tools to create directory structures
          - **Data Analysis**: Tools to read and process the WhatsApp source data
          - **Git Operations**: If needed for repository management
          
          Use these tools systematically to:
          1. Read the WhatsApp data source: `whatsapp_data_for_gemini.txt`
          2. Create the required directory structure: `daily_production/data/YYYY-MM/DD/`
          3. Generate JSON files with structured production data
          4. Create Markdown reports for human readability
          5. Validate all file creation was successful
          
          ## Important Notes
          
          - **File Paths**: Use absolute paths relative to repository root
          - **Data Integrity**: Never fabricate data - extract only from WhatsApp source
          - **Validation**: Include source quotes for all extracted metrics
          - **Quality**: Follow professional standards for both JSON schema and Markdown formatting
          
          **CRITICAL**: This is production data processing for actual mining operations. Accuracy is paramount.
    
    - name: Verify File Creation
      id: verify_files
      if: steps.gemini_process.conclusion == 'success'
      run: |
        TARGET_DATE="${{ github.event.inputs.date }}"
        YEAR_MONTH=$(echo $TARGET_DATE | cut -d'-' -f1,2)
        DAY=$(echo $TARGET_DATE | cut -d'-' -f3)
        TARGET_DIR="daily_production/data/${YEAR_MONTH}/${DAY}"
        
        echo "ðŸ” Verifying files were created by Gemini production processing in: $TARGET_DIR"
        
        # Count actual files created
        JSON_FILES=$(find "$TARGET_DIR" -name "*.json" 2>/dev/null | wc -l || echo "0")
        MD_FILES=$(find "$TARGET_DIR" -name "*.md" 2>/dev/null | wc -l || echo "0")
        TOTAL_FILES=$((JSON_FILES + MD_FILES))
        
        echo "ðŸ“Š Verification: $JSON_FILES JSON, $MD_FILES Markdown = $TOTAL_FILES total files"
        
        # List created files
        if [ -d "$TARGET_DIR" ]; then
          echo "ðŸ“‚ Files in $TARGET_DIR:"
          ls -la "$TARGET_DIR" || echo "Directory exists but is empty"
        else
          echo "âš ï¸ Target directory does not exist"
        fi
        
        # Validation check
        if [ "$TOTAL_FILES" -gt 0 ]; then
          echo "âœ… Files were created by Gemini ($TOTAL_FILES total)"
        else
          echo "âŒ No files were created by Gemini"
        fi
        
        echo "json_files_count=$JSON_FILES" >> $GITHUB_OUTPUT
        echo "md_files_count=$MD_FILES" >> $GITHUB_OUTPUT
        echo "total_files=$TOTAL_FILES" >> $GITHUB_OUTPUT
        echo "target_dir=$TARGET_DIR" >> $GITHUB_OUTPUT