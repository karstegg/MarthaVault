name: ü§ñ Gemini AI PDR Processing

on:
  repository_dispatch:
    types: [gemini-test]

jobs:
  gemini-pdr-processing:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      issues: write
      pull-requests: write
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Check Bridge Health & Extract WhatsApp Messages
      env:
        GH_TOKEN: ${{ secrets.PAT_WITH_CODESPACE }}
      id: extract
      run: |
        CODESPACE_NAME="cuddly-guacamole-496vp6p46wg39r"
        TARGET_DATE="${{ github.event.client_payload.date }}"
        ADDITIONAL_INSTRUCTIONS="${{ github.event.client_payload.instructions }}"
        
        echo "üîç Checking WhatsApp bridge health and extracting messages for $TARGET_DATE..."
        
        # Check if bridge service is running and restart if needed
        echo "üîß Checking bridge service status..."
        BRIDGE_STATUS=$(gh codespace ssh -c $CODESPACE_NAME -- \
          "cd /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge && ./start-bridge-service.sh status" 2>/dev/null || echo "Bridge not running")
        
        if [[ "$BRIDGE_STATUS" == *"not running"* ]]; then
          echo "üö® Bridge not running - starting service..."
          gh codespace ssh -c $CODESPACE_NAME -- \
            "cd /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge && ./start-bridge-service.sh start"
          sleep 10  # Give bridge time to start
          echo "‚úÖ Bridge service started"
        else
          echo "‚úÖ Bridge service is running"
        fi
        
        # Extract messages from Codespace SQLite database
        echo "üìã Extracting messages with production keywords..."
        gh codespace ssh -c $CODESPACE_NAME -- \
          "sqlite3 /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge/store/messages.db \"SELECT timestamp, chat_jid, sender, content FROM messages WHERE timestamp BETWEEN '${TARGET_DATE} 00:00:00+00:00' AND '${TARGET_DATE} 23:59:59+00:00' AND chat_jid = '27834418149-1537194373@g.us' AND (content LIKE '%ROM%' OR content LIKE '%Safety%' OR content LIKE '%Gloria Report%' OR content LIKE '%Nchwaning%' OR content LIKE '%S&W%' OR content LIKE '%Decline%' OR content LIKE '%Product%' OR content LIKE '%Loads%') ORDER BY timestamp;\"" > extracted_messages.txt
        
        # Debug: Check if file was created and has content
        if [ -f extracted_messages.txt ]; then
          echo "‚úÖ Extraction file created"
          echo "üìÑ File size: $(stat -c%s extracted_messages.txt 2>/dev/null || stat -f%z extracted_messages.txt 2>/dev/null || echo 'unknown') bytes"
        else
          echo "‚ùå Extraction file not created"
        fi
           
        # Count messages and validate extraction
        MESSAGE_COUNT=$(wc -l < extracted_messages.txt)
        echo "üìä Found $MESSAGE_COUNT WhatsApp messages for $TARGET_DATE"
        
        # Log if no data found (but don't exit - let conditional handle it)
        if [ "$MESSAGE_COUNT" -eq 0 ]; then
          echo "‚ö†Ô∏è  No production messages found for $TARGET_DATE"
          echo "Data may not be available or date may be incorrect"
        fi
        
        # Output variables for next steps
        echo "message_count=$MESSAGE_COUNT" >> $GITHUB_OUTPUT
        echo "target_date=$TARGET_DATE" >> $GITHUB_OUTPUT
        
        # CRITICAL FIX: Save extracted data for Gemini processing (GitHub Actions has multiline output limits)
        if [ "$MESSAGE_COUNT" -gt 0 ]; then
          # Copy data to workspace for Gemini access
          cp extracted_messages.txt whatsapp_data_for_gemini.txt
          echo "data_file_created=true" >> $GITHUB_OUTPUT
        else
          echo "data_file_created=false" >> $GITHUB_OUTPUT
        fi
        
        # Preview extracted data (first 3 lines)
        echo "üìã Message preview:"
        head -3 extracted_messages.txt || echo "No data to preview"
    
    - name: Handle No Data Found
      env:
        GH_TOKEN: ${{ secrets.PAT_WITH_CODESPACE }}
      if: steps.extract.outputs.message_count == '0'
      run: |
        TARGET_DATE="${{ steps.extract.outputs.target_date }}"
        echo "üõë STOPPING PROCESSING - No data available for $TARGET_DATE"
        echo "Possible reasons:"
        echo "  - Date may be a weekend/holiday with no reports"
        echo "  - Bridge may have been offline during report time"
        echo "  - Reports may use different keywords not in search filter"
        echo "  - Date format may be incorrect (use YYYY-MM-DD)"
        
        # Create a no-data notification issue
        gh issue create \
          --title "‚ùå No Data Found (Gemini): $TARGET_DATE" \
          --body "**No production data available for $TARGET_DATE**

        üìä **Search Results**: 0 messages found
        üîç **Search Criteria**: ROM, Production, Gloria, Nchwaning, S&W keywords
        ‚è∞ **Time Range**: Full day (00:00-23:59 UTC)
        ü§ñ **Processing**: Gemini AI CLI action workflow
        
        **Possible Reasons**:
        - Weekend/holiday - no production reports sent
        - WhatsApp bridge offline during report time (4:00-6:00 AM SAST)
        - Engineers used different messaging keywords
        - Date format incorrect or date does not exist
        
        **Bridge Status**: Checked and restarted if needed
        **Recommendation**: Verify date and retry, or process manually if reports exist" \
          --label "no-data" \
          --label "pdr-gemini"
        
        echo "‚úÖ Created no-data notification issue"
        
    - name: Process with Gemini AI (Direct File Creation)
      uses: 'google-github-actions/run-gemini-cli@v0'
      id: gemini_process
      if: steps.extract.outputs.message_count > 0
      env:
        TARGET_DATE: ${{ github.event.client_payload.date }}
        MESSAGE_COUNT: ${{ steps.extract.outputs.message_count }}
        WHATSAPP_DATA_FILE: whatsapp_data_for_gemini.txt
      with:
        gemini_api_key: ${{ secrets.GEMINI_API_KEY }}
        settings: |
          {
            "maxSessionTurns": 20,
            "autoAccept": ["list_directory", "read_file", "write_file", "glob", "search_file_content", "replace"],
            "telemetry": {
              "enabled": false
            }
          }
        prompt: |
          You are processing daily production reports for Assmang's Black Rock mining operations.
          
          **TASK**: Process the WhatsApp production data and create actual JSON and Markdown files for each detected mine site.
          
          **SITES TO PROCESS**:
          - Gloria Mine (Engineer: Sipho Dubazane)
          - Nchwaning 2 (Engineer: Sikelela Nzuza) 
          - Nchwaning 3 (Engineer: Sello Sease)
          - Shafts & Winders (Engineer: Xavier Peterson)
          
          **REQUIREMENTS**:
          1. Use available shell commands to create actual files in the repository
          2. Follow the exact JSON schema and Markdown template provided in GEMINI.md  
          3. NEVER INVENT DATA - extract only actual values from source
          4. Include source_validation section for all extracted data
          5. Use null for missing data, do not fabricate
          6. Use target date: ${{ env.TARGET_DATE }} for all file content and naming
          
          **FILE CREATION INSTRUCTIONS**:
          1. Use the `write_file` tool to create files directly in the repository
          2. For each site detected in the data:
             - Create JSON file using: write_file(file_path="daily_production/data/2025-07/14/2025-07-14_[site].json", content="[json_content]")
             - Create Markdown file using: write_file(file_path="daily_production/data/2025-07/14/2025-07-14 ‚Äì [Site Name] Daily Report.md", content="[markdown_content]")
          
          **CRITICAL**: 
          - Follow GEMINI.md configuration exactly
          - Every data point must be traceable to source
          - Use your write_file tool to create actual files in the repository
          - NEVER INVENT DATA - extract only actual values from source
          
          **TASK STEPS**:
          1. Use read_file tool to read WhatsApp data file: whatsapp_data_for_gemini.txt
          2. Use read_file tool to read GEMINI.md to understand templates and schemas
          3. Analyze the data and identify mine sites (Gloria, Nchwaning 2, Nchwaning 3, Shafts & Winders)
          4. For each site found in data: use write_file tool to create both JSON and Markdown files
          5. Follow exact JSON schema and Markdown template from GEMINI.md
          6. Confirm file creation success for each file created
    
    - name: Verify File Creation
      id: verify_files
      if: steps.gemini_process.conclusion == 'success'
      run: |
        TARGET_DATE="${{ github.event.client_payload.date }}"
        YEAR_MONTH=$(echo $TARGET_DATE | cut -d'-' -f1,2)
        DAY=$(echo $TARGET_DATE | cut -d'-' -f3)
        TARGET_DIR="daily_production/data/${YEAR_MONTH}/${DAY}"
        
        echo "üîç Verifying files were created by Gemini direct creation in: $TARGET_DIR"
        
        # Count actual files created
        JSON_FILES=$(find "$TARGET_DIR" -name "*.json" 2>/dev/null | wc -l || echo "0")
        MD_FILES=$(find "$TARGET_DIR" -name "*.md" 2>/dev/null | wc -l || echo "0")
        TOTAL_FILES=$((JSON_FILES + MD_FILES))
        
        echo "üìä Verification: $JSON_FILES JSON, $MD_FILES Markdown = $TOTAL_FILES total files"
        
        # List created files
        if [ -d "$TARGET_DIR" ]; then
          echo "üìÇ Files in $TARGET_DIR:"
          ls -la "$TARGET_DIR" || echo "Directory exists but is empty"
        else
          echo "‚ö†Ô∏è Target directory does not exist"
        fi
        
        # Validation check
        if [ "$TOTAL_FILES" -gt 0 ]; then
          echo "‚úÖ Files were created by Gemini ($TOTAL_FILES total)"
        else
          echo "‚ùå No files were created by Gemini"
        fi
        
        echo "json_files_count=$JSON_FILES" >> $GITHUB_OUTPUT
        echo "md_files_count=$MD_FILES" >> $GITHUB_OUTPUT
        echo "total_files=$TOTAL_FILES" >> $GITHUB_OUTPUT
        echo "target_dir=$TARGET_DIR" >> $GITHUB_OUTPUT
        
    - name: Validate Generated Files
      id: validate
      run: |
        TARGET_DATE="${{ steps.extract.outputs.target_date }}"
        TARGET_DIR="${{ steps.verify_files.outputs.target_dir }}"
        MESSAGE_COUNT="${{ steps.extract.outputs.message_count }}"
        
        echo "üîç Validating generated files..."
        
        # Validation checks
        VALIDATION_PASSED=true
        VALIDATION_MESSAGES=""
        
        # Check 1: Target directory exists
        if [ -d "$TARGET_DIR" ]; then
          echo "‚úÖ Directory structure correct: $TARGET_DIR"
        else
          echo "‚ùå Target directory not found: $TARGET_DIR"
          VALIDATION_PASSED=false
          VALIDATION_MESSAGES="$VALIDATION_MESSAGES\n- Missing directory: $TARGET_DIR"
        fi
        
        # Check 2: Count generated files
        JSON_COUNT="${{ steps.verify_files.outputs.json_files_count }}"
        MD_COUNT="${{ steps.verify_files.outputs.md_files_count }}"
        TOTAL_FILES="${{ steps.verify_files.outputs.total_files }}"
        
        if [ -d "$TARGET_DIR" ]; then
          
          echo "üìä Found $JSON_COUNT JSON files and $MD_COUNT Markdown files"
          
          # Check for paired files - each JSON should have matching Markdown
          MISSING_PAIRS=""
          for site in gloria nchwaning2 nchwaning3 shafts_winders; do
            JSON_FILE="$TARGET_DIR/${TARGET_DATE}_${site}.json"
            if [ -f "$JSON_FILE" ]; then
              # Check for corresponding markdown file
              MD_EXISTS=false
              for md_file in "$TARGET_DIR"/*Daily\ Report.md "$TARGET_DIR"/*Weekly\ Report.md; do
                if [ -f "$md_file" ] && echo "$md_file" | grep -q -i "$(echo $site | sed 's/shafts_winders/shafts.*winders/g; s/nchwaning/nchwaning/g')"; then
                  MD_EXISTS=true
                  break
                fi
              done
              if [ "$MD_EXISTS" = false ]; then
                MISSING_PAIRS="$MISSING_PAIRS $site"
                echo "‚ùå Missing Markdown report for site: $site (JSON exists)"
              else
                echo "‚úÖ Complete pair for site: $site"
              fi
            fi
          done
          
          if [ -n "$MISSING_PAIRS" ]; then
            echo "‚ùå CRITICAL: Missing Markdown reports for sites:$MISSING_PAIRS"
            VALIDATION_PASSED=false
            VALIDATION_MESSAGES="$VALIDATION_MESSAGES\n- Missing Markdown reports for:$MISSING_PAIRS"
            VALIDATION_MESSAGES="$VALIDATION_MESSAGES\n- This indicates Gemini AI partial failure"
          fi
          
          # Check 3: File size validation (not empty)
          if [ "$TOTAL_FILES" -gt 0 ]; then
            EMPTY_FILES=$(find "$TARGET_DIR" \( -name "*.json" -o -name "*.md" \) -empty | wc -l)
            if [ "$EMPTY_FILES" -eq 0 ]; then
              echo "‚úÖ No empty files detected"
            else
              echo "‚ùå Found $EMPTY_FILES empty files"
              VALIDATION_PASSED=false
              VALIDATION_MESSAGES="$VALIDATION_MESSAGES\n- $EMPTY_FILES empty files detected"
            fi
          fi
        else
          TOTAL_FILES=0
        fi
        
        # Output validation results
        echo "validation_passed=$VALIDATION_PASSED" >> $GITHUB_OUTPUT
        echo "total_files=$TOTAL_FILES" >> $GITHUB_OUTPUT
        echo "json_count=$JSON_COUNT" >> $GITHUB_OUTPUT
        echo "md_count=$MD_COUNT" >> $GITHUB_OUTPUT
        
        if [ "$VALIDATION_PASSED" = false ]; then
          echo "‚ùå Validation failed. Issues:$VALIDATION_MESSAGES"
        else
          echo "‚úÖ All validations passed"
        fi
        
    - name: Create Pull Request
      env:
        GH_TOKEN: ${{ secrets.PAT_WITH_CODESPACE }}
      if: steps.validate.outputs.validation_passed == 'true'
      id: pr
      run: |
        TARGET_DATE="${{ steps.extract.outputs.target_date }}"
        MESSAGE_COUNT="${{ steps.extract.outputs.message_count }}"
        TOTAL_FILES="${{ steps.validate.outputs.total_files }}"
        JSON_COUNT="${{ steps.validate.outputs.json_count }}"
        MD_COUNT="${{ steps.validate.outputs.md_count }}"
        YEAR_MONTH=$(echo $TARGET_DATE | cut -d'-' -f1,2)
        DAY=$(echo $TARGET_DATE | cut -d'-' -f3)
        
        # Configure git
        git config --global user.email "noreply@google.com"
        git config --global user.name "Gemini AI"
        
        # Create feature branch
        BRANCH_NAME="gemini/pdr-processing-$TARGET_DATE"
        git checkout -b "$BRANCH_NAME"
        
        # Add generated files
        git add daily_production/data/
        
        # Commit changes
        git commit -m "feat: Gemini AI daily production reports - $TARGET_DATE

        ü§ñ Auto-processed production reports via Gemini AI CLI action
        üìä Processed $MESSAGE_COUNT WhatsApp messages
        üìÅ Generated $TOTAL_FILES files ($JSON_COUNT JSON, $MD_COUNT Markdown)
        üìç Location: daily_production/data/$YEAR_MONTH/$DAY/

        ‚ú® Generated with Gemini AI
        Co-Authored-By: Gemini AI <noreply@google.com>"
        
        # Push branch
        git push origin "$BRANCH_NAME"
        
        # Create PR
        PR_URL=$(gh pr create \
          --title "feat: Gemini AI PDR processing - $TARGET_DATE" \
          --body "$(cat <<EOF
        ## ü§ñ Gemini AI Daily Production Report Processing

        **Date Processed**: $TARGET_DATE  
        **Processing Method**: Free Gemini AI CLI action  
        **Messages Processed**: $MESSAGE_COUNT WhatsApp messages  
        **Files Generated**: $TOTAL_FILES files ($JSON_COUNT JSON + $MD_COUNT Markdown)  

        ### üìä Processing Summary
        - ‚úÖ WhatsApp data extracted from Codespace SQLite database
        - ‚úÖ Processed via Gemini 2.0 Flash Exp model (FREE)
        - ‚úÖ Applied PDR templates and validation rules
        - ‚úÖ Generated structured JSON and readable Markdown files
        - ‚úÖ Auto-validated file structure and content
        - ‚úÖ Zero cost processing (vs \$0.39/day for Claude)

        ### üìÅ Files Location
        \`daily_production/data/$YEAR_MONTH/$DAY/\`

        ### üéØ Quality Assurance
        - All data extracted from source WhatsApp messages
        - Source validation included in JSON files
        - Professional formatting and analysis
        - Follows established Report Templates

        ### üí∞ Cost Comparison
        - **Gemini AI**: FREE (Google AI Studio generous quotas)
        - **Claude Cloud**: \$0.39/day (\$123/year)
        - **Copilot Agent**: \$10/month subscription

        ---
        ü§ñ **Fully autonomous Gemini AI processing** - Ready for review and merge
        EOF
        )" \
          --head "$BRANCH_NAME" \
          --base master)
        
        # Extract PR number
        PR_NUMBER=$(echo $PR_URL | grep -o '[0-9]*$')
        echo "‚úÖ Created PR #$PR_NUMBER: $PR_URL"
        echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
        echo "pr_url=$PR_URL" >> $GITHUB_OUTPUT
        
    - name: Handle Processing Failures
      env:
        GH_TOKEN: ${{ secrets.PAT_WITH_CODESPACE }}
      if: failure()
      run: |
        TARGET_DATE="${{ steps.extract.outputs.target_date }}"
        MESSAGE_COUNT="${{ steps.extract.outputs.message_count }}"
        
        echo "‚ùå Gemini AI processing workflow failed"
        
        # Create failure notification issue
        gh issue create \
          --title "‚ùå Gemini AI Processing Failed: $TARGET_DATE" \
          --body "**Gemini AI Processing Workflow Failed**

        **Date**: $TARGET_DATE  
        **Messages Found**: $MESSAGE_COUNT WhatsApp messages  
        **Status**: Workflow encountered errors during processing
        
        **Possible Issues**:
        - Gemini API key missing or invalid
        - Gemini AI model unavailable or rate limited
        - File generation or organization failures
        - Validation errors
        - GitHub API errors
        
        **Next Steps**:
        - Check workflow logs for specific error details
        - Verify GEMINI_API_KEY secret is configured
        - Verify Codespace is active and accessible
        - Try fallback to Claude processing: \`/pdr-cloud $TARGET_DATE\`
        - Issue left open for manual resolution
        
        **Debug**: Check GitHub Actions logs for this workflow run
        **Fallback Available**: Use \`/pdr-cloud\` command if Gemini fails" \
          --label "gemini-failure" \
          --label "pdr-gemini"
        
        echo "üìù Created failure notification issue"
        
    - name: Success Summary
      if: success() && steps.validate.outputs.validation_passed == 'true'
      run: |
        TARGET_DATE="${{ steps.extract.outputs.target_date }}"
        MESSAGE_COUNT="${{ steps.extract.outputs.message_count }}"
        TOTAL_FILES="${{ steps.validate.outputs.total_files }}"
        PR_NUMBER="${{ steps.pr.outputs.pr_number }}"
        
        echo "üéâ Gemini AI processing completed successfully!"
        echo ""
        echo "üìä **Processing Summary**:"
        echo "- Date: $TARGET_DATE"
        echo "- Messages: $MESSAGE_COUNT WhatsApp messages"
        echo "- Files: $TOTAL_FILES generated files"
        echo "- PR: #$PR_NUMBER created and ready for review"
        echo "- Cost: FREE (Gemini AI)"
        echo ""
        echo "‚úÖ Ready for manual review and merge"