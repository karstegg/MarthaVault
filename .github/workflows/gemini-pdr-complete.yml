name: ðŸ¤– Gemini Complete PDR Processing

on:
  issue_comment:
    types: [created]

jobs:
  gemini-pdr-complete:
    if: contains(github.event.comment.body, '@gemini-pdr') && contains(fromJSON('["OWNER", "MEMBER", "COLLABORATOR"]'), github.event.comment.author_association)
    runs-on: ubuntu-latest
    permissions:
      contents: write
      issues: write
      pull-requests: write
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Extract Date from Comment
      id: extract_date
      run: |
        COMMENT_BODY="${{ github.event.comment.body }}"
        
        # Extract date pattern YYYY-MM-DD from comment
        DATE_PATTERN=$(echo "$COMMENT_BODY" | grep -oE '[0-9]{4}-[0-9]{2}-[0-9]{2}' | head -1)
        
        if [ -z "$DATE_PATTERN" ]; then
          echo "âŒ No date found in comment. Please include a date in YYYY-MM-DD format."
          exit 1
        fi
        
        echo "target_date=$DATE_PATTERN" >> $GITHUB_OUTPUT
        echo "âœ… Extracted target date: $DATE_PATTERN"
        
    - name: Check Bridge Health & Extract WhatsApp Messages
      env:
        GH_TOKEN: ${{ secrets.PAT_WITH_CODESPACE }}
      id: extract
      run: |
        CODESPACE_NAME="cuddly-guacamole-496vp6p46wg39r"
        TARGET_DATE="${{ steps.extract_date.outputs.target_date }}"
        
        echo "ðŸ” Checking WhatsApp bridge health and extracting messages for $TARGET_DATE..."
        
        # Check if bridge service is running and restart if needed
        echo "ðŸ”§ Checking bridge service status..."
        BRIDGE_STATUS=$(gh codespace ssh -c $CODESPACE_NAME -- \
          "cd /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge && ./start-bridge-service.sh status" 2>/dev/null || echo "Bridge not running")
        
        if [[ "$BRIDGE_STATUS" == *"not running"* ]]; then
          echo "ðŸš¨ Bridge not running - starting service..."
          gh codespace ssh -c $CODESPACE_NAME -- \
            "cd /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge && ./start-bridge-service.sh start"
          sleep 10  # Give bridge time to start
          echo "âœ… Bridge service started"
        else
          echo "âœ… Bridge service is running"
        fi
        
        # Extract messages from Codespace SQLite database
        echo "ðŸ“‹ Extracting messages with production keywords..."
        gh codespace ssh -c $CODESPACE_NAME -- \
          "sqlite3 /workspaces/MarthaVault/whatsapp-mcp/whatsapp-bridge/store/messages.db \"SELECT timestamp, chat_jid, sender, content FROM messages WHERE timestamp BETWEEN '${TARGET_DATE} 00:00:00+00:00' AND '${TARGET_DATE} 23:59:59+00:00' AND chat_jid = '27834418149-1537194373@g.us' AND (content LIKE '%ROM%' OR content LIKE '%Safety%' OR content LIKE '%Gloria Report%' OR content LIKE '%Nchwaning%' OR content LIKE '%S&W%' OR content LIKE '%Decline%' OR content LIKE '%Product%' OR content LIKE '%Loads%') ORDER BY timestamp;" > extracted_messages.txt
        
        # Count messages and validate extraction
        MESSAGE_COUNT=$(wc -l < extracted_messages.txt)
        echo "ðŸ“Š Found $MESSAGE_COUNT WhatsApp messages for $TARGET_DATE"
        
        # Output variables for next steps
        echo "message_count=$MESSAGE_COUNT" >> $GITHUB_OUTPUT
        echo "target_date=$TARGET_DATE" >> $GITHUB_OUTPUT
        
        # Save extracted data for Gemini processing
        if [ "$MESSAGE_COUNT" -gt 0 ]; then
          cp extracted_messages.txt whatsapp_data_for_gemini.txt
          echo "data_file_created=true" >> $GITHUB_OUTPUT
        else
          echo "data_file_created=false" >> $GITHUB_OUTPUT
        fi
        
        # Preview extracted data (first 3 lines)
        echo "ðŸ“‹ Message preview:"
        head -3 extracted_messages.txt || echo "No data to preview"
    
    - name: Handle No Data Found
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      if: steps.extract.outputs.message_count == '0'
      run: |
        TARGET_DATE="${{ steps.extract.outputs.target_date }}"
        ISSUE_NUMBER="${{ github.event.issue.number }}"
        
        echo "ðŸ›‘ STOPPING PROCESSING - No data available for $TARGET_DATE"
        
        # Add comment to the issue explaining no data found
        gh issue comment "$ISSUE_NUMBER" --body "âŒ **No Production Data Found for $TARGET_DATE**

ðŸ“Š **Search Results**: 0 messages found
ðŸ” **Search Criteria**: ROM, Production, Gloria, Nchwaning, S&W keywords  
â° **Time Range**: Full day (00:00-23:59 UTC)
ðŸ¤– **Processing**: Gemini Complete PDR workflow

**Possible Reasons**:
- Weekend/holiday - no production reports sent
- WhatsApp bridge offline during report time (4:00-6:00 AM SAST)
- Engineers used different messaging keywords
- Date format incorrect or date does not exist

**Bridge Status**: âœ… Checked and restarted if needed
**Recommendation**: Verify date and retry, or process manually if reports exist"
        
        echo "âœ… Added no-data comment to issue #$ISSUE_NUMBER"
        
    - name: Process with Gemini AI (Complete PDR Logic)
      uses: 'google-github-actions/run-gemini-cli@v0'
      id: gemini_process
      if: steps.extract.outputs.message_count > 0
      env:
        TARGET_DATE: ${{ steps.extract.outputs.target_date }}
        MESSAGE_COUNT: ${{ steps.extract.outputs.message_count }}
        ISSUE_NUMBER: ${{ github.event.issue.number }}
      with:
        gemini_api_key: ${{ secrets.GEMINI_API_KEY }}
        settings: |-
          {
            "maxSessionTurns": 50,
            "telemetry": {
              "enabled": false,
              "target": "gcp"
            }
          }
        prompt: |-
          ## Role
          
          You are a specialized AI assistant for processing daily production reports for Assmang's Black Rock mining operations. You have full access to all available tools to interact with the repository, create files, and manage the workflow.
          
          ## Context
          
          - **Repository**: `${{ github.repository }}`
          - **Processing Date**: `${{ env.TARGET_DATE }}`
          - **Messages Found**: `${{ env.MESSAGE_COUNT }}`
          - **Data Source**: WhatsApp production reports from mine engineers
          - **Output Required**: JSON and Markdown files for each mine site
          - **Issue Number**: `${{ env.ISSUE_NUMBER }}`
          
          ## Task: Complete Daily Production Report Processing
          
          You need to process WhatsApp production data and create comprehensive daily reports for each detected mine site.
          
          **SITES TO PROCESS**:
          - Gloria Mine (Engineer: Sipho Dubazane)
          - Nchwaning 2 (Engineer: Sikelela Nzuza) 
          - Nchwaning 3 (Engineer: Sello Sease)
          - Shafts & Winders (Engineer: Xavier Peterson)
          
          ## Step-by-Step Processing Instructions
          
          ### Step 1: Read WhatsApp Data
          First, read the extracted WhatsApp data:
          ```
          cat whatsapp_data_for_gemini.txt
          ```
          
          ### Step 2: Create Directory Structure
          Ensure the proper directory structure exists:
          ```
          mkdir -p daily_production/data/${{ env.TARGET_DATE:0:7 }}/${{ env.TARGET_DATE:8:2 }}
          ```
          
          ### Step 3: Process Each Mine Site
          For each site detected in the data, create both JSON and Markdown files.
          
          **JSON File Format** (`YYYY-MM-DD_[site].json`):
          ```json
          {
            "report_metadata": {
              "date": "${{ env.TARGET_DATE }}",
              "site": "[Site Name]",
              "engineer": "[Engineer Name]",
              "processing_method": "gemini_complete_automated"
            },
            "safety": {
              "status": "[extracted from source]",
              "incidents": [number]
            },
            "production": {
              "rom": {"actual": [number], "unit": "tonnes"},
              "decline": {"actual": [number], "unit": "metres"},
              "product": {"actual": [number], "unit": "tonnes"}
            },
            "equipment_availability": {
              "tmm": {
                "DT": [percentage],
                "FL": [percentage]
              }
            },
            "source_validation": {
              "rom_actual": {
                "value": [number],
                "source_quote": "[exact text from WhatsApp]",
                "confidence": "HIGH|MEDIUM|LOW"
              }
            }
          }
          ```
          
          **Markdown File Format** (`YYYY-MM-DD â€“ [Site Name] Daily Report.md`):
          Create professional daily reports with:
          - Summary of operations
          - Key production metrics
          - Safety status
          - Equipment performance
          - Issues or concerns
          
          ### Step 4: Data Validation Requirements
          
          **CRITICAL DATA INTEGRITY RULES**:
          - **NEVER INVENT DATA**: Extract only actual values from the WhatsApp source
          - **Source Traceability**: Every data point must reference the exact source text
          - **Use null for missing data**: If a metric isn't in the source, use `null`
          - **Quote Accuracy**: Include exact quotes from WhatsApp messages
          - **Confidence Levels**: Mark data confidence as HIGH/MEDIUM/LOW based on clarity
          
          ### Step 5: Create Issue Response
          After creating all files, add a summary comment to issue #${{ env.ISSUE_NUMBER }}:
          
          ```
          gh issue comment ${{ env.ISSUE_NUMBER }} --body "âœ… **Gemini PDR Processing Complete for ${{ env.TARGET_DATE }}**
          
          ðŸ“Š **Data Processed**: ${{ env.MESSAGE_COUNT }} WhatsApp messages
          ðŸ­ **Sites Detected**: [List sites found]
          ðŸ“ **Files Created**: [List files created with paths]
          
          **Summary**: [Brief summary of processing results]
          
          ðŸ”— **Review Files**: Check the daily_production/data/${{ env.TARGET_DATE:0:7 }}/${{ env.TARGET_DATE:8:2 }}/ directory
          ðŸ¤– **Processing Method**: Gemini Complete Automated"
          ```
          
          ## Guidelines
          
          - **Be systematic and thorough**: Process all data found
          - **Maintain data integrity**: Every piece of data must be traceable to the source
          - **Use absolute file paths**: Always use full paths for file operations
          - **Create professional output**: Both JSON and Markdown should be well-formatted
          - **Handle errors gracefully**: If data is missing or unclear, document this clearly
          - **Follow project conventions**: Use the established file naming and directory structure
          
          ## Success Criteria
          
          - [ ] WhatsApp data successfully analyzed
          - [ ] All mine sites identified and processed
          - [ ] JSON files created with complete schema
          - [ ] Markdown reports generated for readability
          - [ ] All data points validated against source
          - [ ] Files properly organized in directory structure
          - [ ] Issue comment posted with summary
          
          **Begin processing the production data for ${{ env.TARGET_DATE }} now.**
          
          **CRITICAL**: This is production data processing for actual mining operations. Accuracy is paramount.
    
    - name: Verify File Creation
      id: verify_files
      if: steps.gemini_process.conclusion == 'success'
      run: |
        TARGET_DATE="${{ steps.extract.outputs.target_date }}"
        YEAR_MONTH=$(echo $TARGET_DATE | cut -d'-' -f1,2)
        DAY=$(echo $TARGET_DATE | cut -d'-' -f3)
        TARGET_DIR="daily_production/data/${YEAR_MONTH}/${DAY}"
        
        echo "ðŸ” Verifying files were created by Gemini Complete processing in: $TARGET_DIR"
        
        # Count actual files created
        JSON_FILES=$(find "$TARGET_DIR" -name "*.json" 2>/dev/null | wc -l || echo "0")
        MD_FILES=$(find "$TARGET_DIR" -name "*.md" 2>/dev/null | wc -l || echo "0")
        TOTAL_FILES=$((JSON_FILES + MD_FILES))
        
        echo "ðŸ“Š Verification: $JSON_FILES JSON, $MD_FILES Markdown = $TOTAL_FILES total files"
        
        # List created files
        if [ -d "$TARGET_DIR" ]; then
          echo "ðŸ“‚ Files in $TARGET_DIR:"
          ls -la "$TARGET_DIR" || echo "Directory exists but is empty"
        else
          echo "âš ï¸ Target directory does not exist"
        fi
        
        # Validation check
        if [ "$TOTAL_FILES" -gt 0 ]; then
          echo "âœ… Files were created by Gemini Complete ($TOTAL_FILES total)"
        else
          echo "âŒ No files were created by Gemini Complete"
        fi
        
        echo "json_files_count=$JSON_FILES" >> $GITHUB_OUTPUT
        echo "md_files_count=$MD_FILES" >> $GITHUB_OUTPUT
        echo "total_files=$TOTAL_FILES" >> $GITHUB_OUTPUT
        echo "target_dir=$TARGET_DIR" >> $GITHUB_OUTPUT